{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport zipfile\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\nimport shutil\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div dir=\"rtl\">\n    به دلیل اینکه در محیط Kaggle در حال توسعه هستم، شکل ورودی ها متفاوت هستند\n</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_dir = '/kaggle/input/gender-classification-dataset/Training'\nval_data_dir = '/kaggle/input/gender-classification-dataset/Validation'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"paths_dict = {\n    'female': [],\n    'male': []\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for key in paths_dict.keys():\n    for dirname, _, filenames in os.walk(os.path.join(train_data_dir, key)):\n        for filename in filenames:\n            paths_dict[key].append(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"groups = [key + '\\n' + str(len(paths_dict[key])) \n          for key in paths_dict.keys()]\ncount_data = [len(paths_dict[key])\n          for key in paths_dict.keys()]\ncolors = ['b', 'r']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualization of the amount of train data in classes"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Amount of train data')\n\nwidth = len(count_data) * 0.3\nplt.bar(groups, count_data, width=width, color=colors, alpha=0.6, bottom=2, linewidth=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creation of directories for generators"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = '/kaggle/working/train_dir'\ntest_dir = '/kaggle/working/test_dir'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_directory(dir_name):\n    if os.path.exists(dir_name):\n        shutil.rmtree(dir_name)\n    os.makedirs(dir_name)\n    \n    for key in paths_dict.keys():\n        os.makedirs(os.path.join(dir_name, key))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_directory(train_dir)\ncreate_directory(test_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def copy_images(start_index, end_index, paths, dest_dir):\n    for i in range(start_index, end_index):\n        dest_path = os.path.join(dest_dir, paths[i].split('/')[5])\n        shutil.copy2(paths[i], dest_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Part of the test data set\ntest_data_proportion = 0.2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for key in paths_dict.keys():\n    test_index = len(paths_dict[key]) - int(len(paths_dict[key]) * test_data_proportion)\n    \n    copy_images(0, test_index, paths_dict[key], train_dir)\n    copy_images(test_index, len(paths_dict[key]), paths_dict[key], test_dir)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div dir=\"rtl\">در اینجا یادگیری انتقالی با استفاده از inception_v3 انجام شده است. هر چند گزینه های متفاوتی برای این کار وجود دارد.</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the inception model  \nfrom tensorflow.keras.applications.inception_v3 import InceptionV3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div dir=\"rtl\">وزن ها نیز از شبکه imagenet گرفته میشود.</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"pre_trained_model = InceptionV3(input_shape = (150, 150, 3), # Shape of our images\n                                include_top = False, # Leave out the last fully connected layer\n                                weights = 'imagenet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in pre_trained_model.layers:\n  layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div dir=\"rtl\">مانند تمرین های پیش با قرار دادن این شرط بر روی هر epoch از overfit شدن شبکه جلوگیری میکنیم.</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"class myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs={}):\n    if(logs.get('acc')>0.959):\n      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n      self.model.stop_training = True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"کراس به صورت پیش فرض این معیارهای سنجش را ندارد. پس ما آنها را اضافه میکنیم."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\n\ndef recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives =K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div dir=\"rtl\">در ادامه مدل را با چند گزینه متفاوت تست میکنیم و نتایج را ترسیم میکنیم.</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.optimizers import RMSprop\n\nx = layers.Flatten()(pre_trained_model.output)\nx = layers.Dense(1024, activation='relu')(x)\nx = layers.Dropout(0.2)(x)                  \nx = layers.Dense  (1, activation='sigmoid')(x)           \nmodel = Model( pre_trained_model.input, x) \nmodel.compile(optimizer = RMSprop(lr=0.0001), \n              loss = 'binary_crossentropy', \n              metrics = ['acc', f1_m, precision_m, recall_m])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_datagen = ImageDataGenerator(rescale = 1./255.,\n                                   rotation_range = 40,\n                                   width_shift_range = 0.2,\n                                   height_shift_range = 0.2,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\n\ntest_datagen = ImageDataGenerator( rescale = 1.0/255. )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(train_dir,\n                                                    batch_size = 20,\n                                                    class_mode = 'binary', \n                                                    target_size = (150, 150))\nvalidation_generator =  test_datagen.flow_from_directory( val_data_dir,\n                                                          batch_size  = 20,\n                                                          class_mode  = 'binary', \n                                                          target_size = (150, 150))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks = myCallback()\nhistory = model.fit_generator(\n            train_generator,\n            validation_data = validation_generator,\n            steps_per_epoch = 100,\n            epochs = 100,\n            validation_steps = 50,\n            verbose = 2,\n            callbacks=[callbacks])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"F1-score: \",history.history['f1_m'])\nprint(\"F1-score val: \",history.history['val_f1_m'])\nprint(\"Precision: \",history.history['precision_m'])\nprint(\"Precision val: \",history.history['val_precision_m'])\nprint(\"Recall: \",history.history['recall_m'])\nprint(\"Recall: \",history.history['val_recall_m'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_layer = pre_trained_model.get_layer('mixed7') #Only use layers including and above 'mixed7'\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_layer = pre_trained_model.get_layer('mixed7')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output\n\nx = layers.Flatten()(last_output)\nx = layers.Dense(1024, activation='relu')(x)\nx = layers.Dropout(0.2)(x)                  \nx = layers.Dense  (1, activation='sigmoid')(x)           \n\nmodel = Model( pre_trained_model.input, x) \n\nmodel.compile(optimizer = RMSprop(lr=0.0001), \n              loss = 'binary_crossentropy', \n              metrics = ['acc', f1_m, precision_m, recall_m])\n\ntrain_datagen = ImageDataGenerator(rescale = 1./255.,\n                                   rotation_range = 40,\n                                   width_shift_range = 0.2,\n                                   height_shift_range = 0.2,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\ntest_datagen = ImageDataGenerator( rescale = 1.0/255. )\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                    batch_size = 20,\n                                                    class_mode = 'binary', \n                                                    target_size = (150, 150))     \n\nvalidation_generator =  test_datagen.flow_from_directory( val_data_dir,\n                                                          batch_size  = 20,\n                                                          class_mode  = 'binary', \n                                                          target_size = (150, 150))\n\ncallbacks = myCallback()\nhistory = model.fit_generator(\n            train_generator,\n            validation_data = validation_generator,\n            steps_per_epoch = 100,\n            epochs = 100,\n            validation_steps = 50,\n            verbose = 2,\n            callbacks=[callbacks])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"F1-score: \",history.history['f1_m'])\nprint(\"F1-score val: \",history.history['val_f1_m'])\nprint(\"Precision: \",history.history['precision_m'])\nprint(\"Precision val: \",history.history['val_precision_m'])\nprint(\"Recall: \",history.history['recall_m'])\nprint(\"Recall: \",history.history['val_recall_m'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len_train_data = len(train_generator.filenames)\nlen_test_data = len(validation_generator.filenames)\n\nresult = model.evaluate_generator(validation_generator,\n                                  len_test_data // 20,\n                                  verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Train accuracy')\nplt.plot(epochs, val_acc, 'b', label='Val accuracy')\nplt.title('Training & validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Train Loss')\nplt.plot(epochs, val_loss, 'b', label='Val Loss')\nplt.title('Training & validation loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_layer = pre_trained_model.get_layer('mixed7') #Only use layers including and above 'mixed7'\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_layer = pre_trained_model.get_layer('mixed7')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output\n\nx = layers.Flatten()(last_output)\nx = layers.Dense(1024, activation='relu')(x)\nx = layers.Dropout(0.2)(x)                  \nx = layers.Dense  (1, activation='sigmoid')(x)           \n\nmodel = Model( pre_trained_model.input, x) \n\nmodel.compile(optimizer = RMSprop(lr=0.0001), \n              loss = 'binary_crossentropy', \n              metrics = ['acc', f1_m, precision_m, recall_m])\n\ntrain_datagen = ImageDataGenerator(rescale = 1./255.,\n                                   rotation_range = 40,\n                                   width_shift_range = 0.2,\n                                   height_shift_range = 0.2,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\ntest_datagen = ImageDataGenerator( rescale = 1.0/255. )\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                    batch_size = 20,\n                                                    class_mode = 'binary', \n                                                    target_size = (150, 150))     \n\nvalidation_generator =  test_datagen.flow_from_directory( val_data_dir,\n                                                          batch_size  = 20,\n                                                          class_mode  = 'binary', \n                                                          target_size = (150, 150))\n\ncallbacks = myCallback()\nhistory = model.fit_generator(\n            train_generator,\n            validation_data = validation_generator,\n            steps_per_epoch = 100,\n            epochs = 100,\n            validation_steps = 50,\n            verbose = 2,\n            callbacks=[callbacks])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"F1-score: \",history.history['f1_m'])\nprint(\"F1-score val: \",history.history['val_f1_m'])\nprint(\"Precision: \",history.history['precision_m'])\nprint(\"Precision val: \",history.history['val_precision_m'])\nprint(\"Recall: \",history.history['recall_m'])\nprint(\"Recall: \",history.history['val_recall_m'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#batch_size = 20\n\nresult = model.evaluate_generator(validation_generator,\n                                  len_test_data // 20,\n                                  verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(test_gen)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}